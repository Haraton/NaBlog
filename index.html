<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="styles/jemdoc.css" type="text/css" />
<link rel="icon" href="./pics/profile.ico" type="image/x-ico" />

<title>七海Nanamiの技术博客</title>

</head>
<body>

 
<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 


<table class="imgtable">
  <tr>
    <td>
<a href="./"><img src="./pics/profile.jpg" alt="" height="200px" /></a>&nbsp;</td>
<td align="left">
  <p><font size="4">@七海Nanami</font><br />
  <br />
  我们热衷于研究计算机视觉领域相关技术，
  包括图像处理（包括图像生成、图像超分、图像去噪）
  和点云数据处理（包括点云配准、点云特征提取、点云分割、点云去噪）等。
  以下是我们整理的相关文献资料，欢迎各位爱好者一同交流，共同进步！<br />
  <br />
  Email: rofeti9933@alibrs.com <br />
  [<a class="a1" href="https://github.com/Haraton" target="_self">Github</a>]
  [<a class="a2" href="https://Haraton.github.io/NaBlog/" target="_self">HomePage</a>]
  </p>
</td>
</tr>
</table>

<h2>文献综述</h2>
<ul>
  <li> <a href="./brief/点云传统算法总结.html" target="_self">点云传统算法总结</a> </li>
  <li> <a href="./brief/图像超分辨文献.html" target="_self"> 图像超分辨文献综述 </a></li>
  <li> <a href="./brief/图像超分辨文献.html" target="_self">扩散模型综述</a> </li>
  <li> <a href="./brief/图像超分辨文献.html" target="_self">低照度增强综述</a> </li>
  <li> <a href="./brief/图像超分辨文献.html" target="_self">点云补全综述</a> </li>
</ul>


<h2>技术博客</h2>
<ul>
  <li> <a href="https://zhuanlan.zhihu.com/p/161668291" target="_self">彩色图像处理：色彩学基础</a> </li>
  <li> <a href="https://zhuanlan.zhihu.com/p/80852438" target="_self">图像的仿射变换</a></li>
  <li> <a href="https://zhuanlan.zhihu.com/p/645074162" target="_self">霍夫变换(Hough Transform)详解</a> </li>
  <li> <a href="https://zhuanlan.zhihu.com/p/355701873" target="_self">图像压缩技术综述</a> </li>
  <li> <a href="https://blog.csdn.net/weixin_41424926/article/details/101630462" target="_self">数字图像处理——图像退化与复原</a> </li>
  <li> <a href="https://zhuanlan.zhihu.com/p/558813267" target="_self">超分辨率入门综述！</a> </li>
  <li> <a href="https://blog.csdn.net/Wenyuanbo/article/details/125428995" target="_self">图像超分综述:超长文一网打尽图像超分的前世今生</a> </li>
  <li> <a href="https://zhuanlan.zhihu.com/p/407467698" target="_self">CVPR 2021 论文大盘点-超分辨率篇</a> </li>
  <li> <a href="https://zhuanlan.zhihu.com/p/482261337" target="_self">为图像盲超分学习通用的退化模型</a> </li>
  <li> <a href="https://zhuanlan.zhihu.com/p/572770333" target="_self">轻松学习扩散模型（diffusion model），被巨怪踩过的脑袋也能懂</a> </li>
  <li> <a href="https://zhuanlan.zhihu.com/p/139350599" target="_self">走进自动驾驶传感器——激光雷达</a> </li>
  <li> <a href="http://www.bimant.com/blog/5-free-lidar-apps/" target="_self">6个最佳的LiDAR软件</a> </li>
  <li> <a href="https://zhuanlan.zhihu.com/p/107061957" target="_self">3D点云目标检测算法汇总</a> </li>
  <li> <a href="https://zhuanlan.zhihu.com/p/412161451" target="_self">激光雷达：点云语义分割算法</a> </li>
  <li> <a href="https://zhuanlan.zhihu.com/p/591349481" target="_self">3D Segmentation点云语义分割系列论文总结</a> </li>
  <li> <a href="http://www.bimant.com/blog/top8-free-lidar-datasets/" target="_self">8个免费的激光点云数据集</a> </li>
</ul>


<!-- Project -->
<a id="publications" class="anchor"></a>
<h2>经典论文</h2>

<table class="imgtable">

<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/SCUNet/raw/main/figs/real_scunet.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Practical Blind Denoising via Swin-Conv-UNet and Data Synthesis</p>
<p class="pub_author"><b>Kai Zhang</b>, Yawei Li, Jingyun Liang, Jiezhang Cao, Yulun Zhang, Tao Tang, Radu Timofte, Luc Van Gool<br>
ArXiv</i>, 2022.<br>
[<a class="a1" href="https://github.com/JingyunLiang/RVRT" target="_self">Brief</a>] 
[<a class="a2" href= "https://github.com/cszn/SCUNet/blob/6e45b78dba1dfecfadc350d52d659d7701fecf17/figs/scunet.pdf" target="_self">Sourse</a>] 
[<a class="a3" href="https://github.com/cszn/SCUNet" target="_self">Code</a>] 
</p> </td>
</tr>

	
<tr>
<td><img class="proj_thumb" src="https://github.com/JingyunLiang/RVRT/raw/main/assets/teaser_vsr.gif?style=centerme" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Recurrent Video Restoration Transformer with Guided Deformable Attention </p>
<p class="pub_author">Jingyun Liang, Yuchen Fan, Xiaoyu Xiang, Rakesh Ranjan, Eddy Ilg, Simon Green, Jiezhang Cao, <b>Kai Zhang*</b>, Radu Timofte, Luc Van Gool<br>
Thirty-sixth Conference on Neural Information Processing Systems</i> (<b>NeurIPS</b>), 2022.<br>
[<a class="a1" href="./brief/点云处理相关技术调研综述.html" target="_self">Brief</a>] 
[<a class="a2" href= "https://arxiv.org/pdf/2206.02146.pdf" target="_self">Sourse</a>] 
[<a class="a3" href="https://github.com/JingyunLiang/RVRT" target="_self">Code</a>] 
</p> </td>
</tr>	
</table>

	
<div id="footer">
<div id="footer-text">
本站资源均转载自互联网，仅供个人学习使用，如有侵权，请联系本人删除！<br>
All Rights Reserved. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</body>
</html>
