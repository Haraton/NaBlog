<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="styles/jemdoc.css" type="text/css" />
<link rel="icon" href="./pics/profile.ico" type="image/x-ico" />

<title>七海Nanamiの技术博客</title>

</head>
<body>

 
<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 


<table class="imgtable">
  <tr>
    <td>
<a href="./"><img src="./pics/profile.jpg" alt="" height="200px" /></a>&nbsp;</td>
<td align="left">
  <p><font size="4">@七海Nanami</font><br />
  <br />
  我们热衷于研究计算机视觉领域相关技术，
  包括图像处理（包括图像生成、图像超分、图像去噪）
  和点云数据处理（包括点云配准、点云特征提取、点云分割、点云去噪）等。
  以下是我们整理的相关文献资料，欢迎各位爱好者一同交流，共同进步！<br />
  <br />
  Email: rofeti9933@alibrs.com <br />
  [<a class="a1" href="https://github.com/cvml-Robin" target="_self">Github</a>]
  [<a class="a2" href="https://cvml-robin.github.io/" target="_self">HomePage</a>]
  </p>
</td>
</tr>
</table>

<h2>文献综述</h2>
<ul>
  <li> <a href="./brief/点云传统算法总结.html" target="_self">点云传统算法总结</a> </li>
  <li> <a href="./brief/图像超分辨文献.html" target="_self"> 图像超分辨文献综述 </a></li>
  <li> <a href="./brief/图像超分辨文献.html" target="_self">扩散模型综述</a> </li>
  <li> <a href="./brief/图像超分辨文献.html" target="_self">低照度增强综述</a> </li>
  <li> <a href="./brief/图像超分辨文献.html" target="_self">点云补全综述</a> </li>
</ul>


<h2>技术博客</h2>
<ul>
<li>(2022-07) I will serve as a Senior Program Committee (SPC) Member for AAAI 2023.
<li>I am organizing a Special Issue <a href="https://www.mdpi.com/journal/sensors/special_issues/idisrsa_sensors"  title="updated by Haraton @2022年12月1日" target="_self"><em><strong>"Image Denoising and Image Super-Resolution for Sensing Application"</em></strong></a> on Sensors (IF 3.576), submit your manuscript before 15 December 2022.
<li>We released the testing codes of <a href="https://github.com/cszn/SCUNet" target="_self">SCUNet</a>.</li>
<li>We released the training codes of <a href="https://github.com/cszn/BSRNet" target="_self">BSRNet</a> and <a href="https://github.com/cszn/KAIR/blob/master/docs/README_SwinIR.md" target="_self">SwinIR</a>.</li>
</ul>


<!-- Project -->
<a id="publications" class="anchor"></a>
<h2>经典论文</h2>

<table class="imgtable">

<tr>
<td><img class="proj_thumb" src="https://github.com/cszn/SCUNet/raw/main/figs/real_scunet.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Practical Blind Denoising via Swin-Conv-UNet and Data Synthesis</p>
<p class="pub_author"><b>Kai Zhang</b>, Yawei Li, Jingyun Liang, Jiezhang Cao, Yulun Zhang, Tao Tang, Radu Timofte, Luc Van Gool<br>
ArXiv</i>, 2022.<br>
[<a class="a1" href="https://github.com/JingyunLiang/RVRT" target="_self">Brief</a>] 
[<a class="a2" href= "https://github.com/cszn/SCUNet/blob/6e45b78dba1dfecfadc350d52d659d7701fecf17/figs/scunet.pdf" target="_self">Sourse</a>] 
[<a class="a3" href="https://github.com/cszn/SCUNet" target="_self">Code</a>] 
</p> </td>
</tr>

	
<tr>
<td><img class="proj_thumb" src="https://github.com/JingyunLiang/RVRT/raw/main/assets/teaser_vsr.gif?style=centerme" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Recurrent Video Restoration Transformer with Guided Deformable Attention </p>
<p class="pub_author">Jingyun Liang, Yuchen Fan, Xiaoyu Xiang, Rakesh Ranjan, Eddy Ilg, Simon Green, Jiezhang Cao, <b>Kai Zhang*</b>, Radu Timofte, Luc Van Gool<br>
Thirty-sixth Conference on Neural Information Processing Systems</i> (<b>NeurIPS</b>), 2022.<br>
[<a class="a1" href="./brief/点云处理相关技术调研综述.html" target="_self">Brief</a>] 
[<a class="a2" href= "https://arxiv.org/pdf/2206.02146.pdf" target="_self">Sourse</a>] 
[<a class="a3" href="https://github.com/JingyunLiang/RVRT" target="_self">Code</a>] 
</p> </td>
</tr>	
</table>

	
<div id="footer">
<div id="footer-text">
本站资源均转载自互联网，仅供个人学习使用，如有侵权，请联系本人删除！<br>
All Rights Reserved. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</body>
</html>
